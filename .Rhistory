#Journal of the American Statistical Association 100, no. 470 577-590.
#(Sparse data FPCA)
model0<-FPCA(train$Ly, train$Lt,optns = list(methodSelectK=3))
dim(model0$fiitedCov)
model0$workGrid
#install.packages("fields")
#library(fields)
#quartz()
image.plot(model0$workGrid, model0$workGrid, model0$fittedCov,
xlab="Time",
ylab="Time",lwd=3,cex.axis=2,cex.lab=1.5)
#############################################################################
#The mean curve is estimated by pooling the data for all curves
#together and doing smoothing
#quartz()
dev.off(which=dev.cur())
plot(model0$workGrid, model0$mu, type="l",main="Mean Function",
col="blue",ylim=c(-15,20), xlab="time", ylab="mu(t)",lwd=3,cex.axis=2,cex.lab=1, axes=FALSE)
for (j in 1:35)
{
points(train$Lt[[j]],train$Ly[[j]],col="red",lwd=3)
}
axis(1, monthMid, labels = month.abb)
axis(2, las=1)
#############################################################################
dev.off(which=dev.cur())
plot(model0$workGrid, model0$fittedCov, type="l",main="Mean Function",
col="blue",ylim=c(-15,20), xlab="time", ylab="mu(t)",lwd=3,cex.axis=2,cex.lab=1, axes=FALSE)
for (j in 1:35)
{
points(train$Lt[[j]],train$Ly[[j]],col="red",lwd=3)
}
axis(1, monthMid, labels = month.abb)
axis(2, las=1)
##########################################################################
#quartz()
dev.off(which=dev.cur())
par(mfrow=c(1,3))
plot(model0$workGrid,-model0$phi[,1],type="l",ylim = c(-0.1,0.1),main= paste("PCA 1"," (",as.character(round(model0$cumFVE[1]*100)),"%)", sep=""),
col="blue",xlab="Time", ylab="First FPC",lwd=3,cex.axis=1,cex.lab=1,axes=FALSE)
abline(h=0, lty="dashed")
axis(1, monthMid, labels = month.abb)
axis(2, las=1)
plot(model0$workGrid,-model0$phi[,2],type="l",ylim = c(-0.1,0.1),main= paste("PCA 2"," (",as.character(round(diff(model0$cumFVE)[1]*100)),"%)", sep=""),
col="blue",xlab="Time", ylab="Second FPC",lwd=3,cex.axis=1,cex.lab=1,axes=FALSE)
abline(h=0, lty="dashed")
axis(1, monthMid, labels = month.abb)
axis(2, las=1)
plot(model0$workGrid,-model0$phi[,3],type="l",ylim = c(-0.1,0.1),main= paste("PCA 3"," (",as.character(round(diff(model0$cumFVE)[2]*100)),"%)", sep=""),
col="blue",xlab="Time", ylab="Third FPC",lwd=3,cex.axis=1,cex.lab=1,axes=FALSE)
abline(h=0, lty="dashed")
axis(1, monthMid, labels = month.abb)
axis(2, las=1)
############
pts<-seq(1,365)
sparsity<-2:5
#set.seed(5)#3 , 5 works good if you negate it and you can because
#the absolute values of PCA is all that matters (i negated the PCA values later)
train<-Sparsify(densedata[c(1:35), ,drop=FALSE],pts,sparsity)
test<-Sparsify(densedata[c(18:35), ,drop=FALSE],pts,sparsity)
#quartz()
op<-par(mfrow=c(2,2))
for (j in 1:4)
{
plot(pts, densedata[j,],type="l",lwd=3,
col="black",ylim=c(-10,20), xlab="Time",ylab="True Curve", axes=FALSE,cex.axis=2.5, cex.lab=1)
points(train$Lt[[j]],train$Ly[[j]],col="red", lwd=3)
axis(1, monthMid, labels = month.abb)
axis(2, las=1)
}
par(op)
#############################################################################
#The FPCA function is conected to Yao, Fang, Müller, Hans-Georg and Wang,
#Jane-Ling (2005). "Functional data analysis for sparse longitudinal data."
#Journal of the American Statistical Association 100, no. 470 577-590.
#(Sparse data FPCA)
model0<-FPCA(train$Ly, train$Lt,optns = list(methodSelectK=3))
dim(model0$fiitedCov)
model0$workGrid
#install.packages("fields")
#library(fields)
#quartz()
image.plot(model0$workGrid, model0$workGrid, model0$fittedCov,
xlab="Time",
ylab="Time",lwd=3,cex.axis=2,cex.lab=1.5)
#############################################################################
#The mean curve is estimated by pooling the data for all curves
#together and doing smoothing
#quartz()
dev.off(which=dev.cur())
plot(model0$workGrid, model0$mu, type="l",main="Mean Function",
col="blue",ylim=c(-15,20), xlab="time", ylab="mu(t)",lwd=3,cex.axis=2,cex.lab=1, axes=FALSE)
for (j in 1:35)
{
points(train$Lt[[j]],train$Ly[[j]],col="red",lwd=3)
}
axis(1, monthMid, labels = month.abb)
axis(2, las=1)
#############################################################################
dev.off(which=dev.cur())
plot(model0$workGrid, model0$fittedCov, type="l",main="Mean Function",
col="blue",ylim=c(-15,20), xlab="time", ylab="mu(t)",lwd=3,cex.axis=2,cex.lab=1, axes=FALSE)
for (j in 1:35)
{
points(train$Lt[[j]],train$Ly[[j]],col="red",lwd=3)
}
axis(1, monthMid, labels = month.abb)
axis(2, las=1)
##########################################################################
#quartz()
dev.off(which=dev.cur())
par(mfrow=c(1,3))
plot(model0$workGrid,-model0$phi[,1],type="l",ylim = c(-0.1,0.1),main= paste("PCA 1"," (",as.character(round(model0$cumFVE[1]*100)),"%)", sep=""),
col="blue",xlab="Time", ylab="First FPC",lwd=3,cex.axis=1,cex.lab=1,axes=FALSE)
abline(h=0, lty="dashed")
axis(1, monthMid, labels = month.abb)
axis(2, las=1)
plot(model0$workGrid,-model0$phi[,2],type="l",ylim = c(-0.1,0.1),main= paste("PCA 2"," (",as.character(round(diff(model0$cumFVE)[1]*100)),"%)", sep=""),
col="blue",xlab="Time", ylab="Second FPC",lwd=3,cex.axis=1,cex.lab=1,axes=FALSE)
abline(h=0, lty="dashed")
axis(1, monthMid, labels = month.abb)
axis(2, las=1)
plot(model0$workGrid,-model0$phi[,3],type="l",ylim = c(-0.1,0.1),main= paste("PCA 3"," (",as.character(round(diff(model0$cumFVE)[2]*100)),"%)", sep=""),
col="blue",xlab="Time", ylab="Third FPC",lwd=3,cex.axis=1,cex.lab=1,axes=FALSE)
abline(h=0, lty="dashed")
axis(1, monthMid, labels = month.abb)
axis(2, las=1)
############
pts<-seq(1,365)
sparsity<-2:5
#set.seed(5)#3 , 5 works good if you negate it and you can because
#the absolute values of PCA is all that matters (i negated the PCA values later)
train<-Sparsify(densedata[c(1:35), ,drop=FALSE],pts,sparsity)
test<-Sparsify(densedata[c(18:35), ,drop=FALSE],pts,sparsity)
#quartz()
op<-par(mfrow=c(2,2))
for (j in 1:4)
{
plot(pts, densedata[j,],type="l",lwd=3,
col="black",ylim=c(-10,20), xlab="Time",ylab="True Curve", axes=FALSE,cex.axis=2.5, cex.lab=1)
points(train$Lt[[j]],train$Ly[[j]],col="red", lwd=3)
axis(1, monthMid, labels = month.abb)
axis(2, las=1)
}
par(op)
#############################################################################
#The FPCA function is conected to Yao, Fang, Müller, Hans-Georg and Wang,
#Jane-Ling (2005). "Functional data analysis for sparse longitudinal data."
#Journal of the American Statistical Association 100, no. 470 577-590.
#(Sparse data FPCA)
model0<-FPCA(train$Ly, train$Lt,optns = list(methodSelectK=3))
dim(model0$fiitedCov)
model0$workGrid
#install.packages("fields")
#library(fields)
#quartz()
image.plot(model0$workGrid, model0$workGrid, model0$fittedCov,
xlab="Time",
ylab="Time",lwd=3,cex.axis=2,cex.lab=1.5)
#############################################################################
#The mean curve is estimated by pooling the data for all curves
#together and doing smoothing
#quartz()
dev.off(which=dev.cur())
plot(model0$workGrid, model0$mu, type="l",main="Mean Function",
col="blue",ylim=c(-15,20), xlab="time", ylab="mu(t)",lwd=3,cex.axis=2,cex.lab=1, axes=FALSE)
for (j in 1:35)
{
points(train$Lt[[j]],train$Ly[[j]],col="red",lwd=3)
}
axis(1, monthMid, labels = month.abb)
axis(2, las=1)
#############################################################################
dev.off(which=dev.cur())
plot(model0$workGrid, model0$fittedCov, type="l",main="Mean Function",
col="blue",ylim=c(-15,20), xlab="time", ylab="mu(t)",lwd=3,cex.axis=2,cex.lab=1, axes=FALSE)
for (j in 1:35)
{
points(train$Lt[[j]],train$Ly[[j]],col="red",lwd=3)
}
axis(1, monthMid, labels = month.abb)
axis(2, las=1)
##########################################################################
#quartz()
dev.off(which=dev.cur())
par(mfrow=c(1,3))
plot(model0$workGrid,-model0$phi[,1],type="l",ylim = c(-0.1,0.1),main= paste("PCA 1"," (",as.character(round(model0$cumFVE[1]*100)),"%)", sep=""),
col="blue",xlab="Time", ylab="First FPC",lwd=3,cex.axis=1,cex.lab=1,axes=FALSE)
abline(h=0, lty="dashed")
axis(1, monthMid, labels = month.abb)
axis(2, las=1)
plot(model0$workGrid,-model0$phi[,2],type="l",ylim = c(-0.1,0.1),main= paste("PCA 2"," (",as.character(round(diff(model0$cumFVE)[1]*100)),"%)", sep=""),
col="blue",xlab="Time", ylab="Second FPC",lwd=3,cex.axis=1,cex.lab=1,axes=FALSE)
abline(h=0, lty="dashed")
axis(1, monthMid, labels = month.abb)
axis(2, las=1)
plot(model0$workGrid,-model0$phi[,3],type="l",ylim = c(-0.1,0.1),main= paste("PCA 3"," (",as.character(round(diff(model0$cumFVE)[2]*100)),"%)", sep=""),
col="blue",xlab="Time", ylab="Third FPC",lwd=3,cex.axis=1,cex.lab=1,axes=FALSE)
abline(h=0, lty="dashed")
axis(1, monthMid, labels = month.abb)
axis(2, las=1)
############
pts<-seq(1,365)
sparsity<-2:5
#set.seed(5)#3 , 5 works good if you negate it and you can because
#the absolute values of PCA is all that matters (i negated the PCA values later)
train<-Sparsify(densedata[c(1:35), ,drop=FALSE],pts,sparsity)
test<-Sparsify(densedata[c(18:35), ,drop=FALSE],pts,sparsity)
#quartz()
op<-par(mfrow=c(2,2))
for (j in 1:4)
{
plot(pts, densedata[j,],type="l",lwd=3,
col="black",ylim=c(-10,20), xlab="Time",ylab="True Curve", axes=FALSE,cex.axis=2.5, cex.lab=1)
points(train$Lt[[j]],train$Ly[[j]],col="red", lwd=3)
axis(1, monthMid, labels = month.abb)
axis(2, las=1)
}
par(op)
#############################################################################
#The FPCA function is conected to Yao, Fang, Müller, Hans-Georg and Wang,
#Jane-Ling (2005). "Functional data analysis for sparse longitudinal data."
#Journal of the American Statistical Association 100, no. 470 577-590.
#(Sparse data FPCA)
model0<-FPCA(train$Ly, train$Lt,optns = list(methodSelectK=3))
dim(model0$fiitedCov)
model0$workGrid
#install.packages("fields")
#library(fields)
#quartz()
image.plot(model0$workGrid, model0$workGrid, model0$fittedCov,
xlab="Time",
ylab="Time",lwd=3,cex.axis=2,cex.lab=1.5)
#############################################################################
#The mean curve is estimated by pooling the data for all curves
#together and doing smoothing
#quartz()
dev.off(which=dev.cur())
plot(model0$workGrid, model0$mu, type="l",main="Mean Function",
col="blue",ylim=c(-15,20), xlab="time", ylab="mu(t)",lwd=3,cex.axis=2,cex.lab=1, axes=FALSE)
for (j in 1:35)
{
points(train$Lt[[j]],train$Ly[[j]],col="red",lwd=3)
}
axis(1, monthMid, labels = month.abb)
axis(2, las=1)
#############################################################################
dev.off(which=dev.cur())
plot(model0$workGrid, model0$fittedCov, type="l",main="Mean Function",
col="blue",ylim=c(-15,20), xlab="time", ylab="mu(t)",lwd=3,cex.axis=2,cex.lab=1, axes=FALSE)
for (j in 1:35)
{
points(train$Lt[[j]],train$Ly[[j]],col="red",lwd=3)
}
axis(1, monthMid, labels = month.abb)
axis(2, las=1)
##########################################################################
#quartz()
dev.off(which=dev.cur())
par(mfrow=c(1,3))
plot(model0$workGrid,-model0$phi[,1],type="l",ylim = c(-0.1,0.1),main= paste("PCA 1"," (",as.character(round(model0$cumFVE[1]*100)),"%)", sep=""),
col="blue",xlab="Time", ylab="First FPC",lwd=3,cex.axis=1,cex.lab=1,axes=FALSE)
abline(h=0, lty="dashed")
axis(1, monthMid, labels = month.abb)
axis(2, las=1)
plot(model0$workGrid,-model0$phi[,2],type="l",ylim = c(-0.1,0.1),main= paste("PCA 2"," (",as.character(round(diff(model0$cumFVE)[1]*100)),"%)", sep=""),
col="blue",xlab="Time", ylab="Second FPC",lwd=3,cex.axis=1,cex.lab=1,axes=FALSE)
abline(h=0, lty="dashed")
axis(1, monthMid, labels = month.abb)
axis(2, las=1)
plot(model0$workGrid,-model0$phi[,3],type="l",ylim = c(-0.1,0.1),main= paste("PCA 3"," (",as.character(round(diff(model0$cumFVE)[2]*100)),"%)", sep=""),
col="blue",xlab="Time", ylab="Third FPC",lwd=3,cex.axis=1,cex.lab=1,axes=FALSE)
abline(h=0, lty="dashed")
axis(1, monthMid, labels = month.abb)
axis(2, las=1)
############
mcar_1 <- delete_MCAR(ds=wine, p=0.1, cols_mis='alcohol')
mean(mcar_1$alcohol, na.rm=TRUE) # 12.99
plot(density(mcar_1$alcohol, na.rm=TRUE)) # looks like a normal mixture
hist(mcar_1$alcohol, breaks=30)
x_mcar_1 <- mcar_1$alcohol[!is.na(mcar_1$alcohol)]
# initial parameters: N(12.4, 0.5) & N(13.7, 0.5)
EM_mcar_1 <- normalmixEM(x_mcar_1, k=2, lambda=c(0.5, 0.5), mu=c(12.4, 13.7),
sigma=c(0.5, 0.5)) # 121 iterations
# new parameter estimates for normal mixture model:
EM_mcar_1$mu
EM_mcar_1$sigma
EM_mcar_1$lambda
setwd('C:/Users/Bethany/OneDrive - University of St Andrews/2021-2023 (Honours)/MT4599 Project - Inference in the Presence of Missing Data/Data/Wine')
library(missMethods)
library(Metrics)
library(rms)
library(pwr)
library(em)
library(mixtools)
wine <- read.table('wine.data', dec='.', sep=',')
colnames(wine) <- c('class', 'alcohol', 'malic acid', 'ash', 'alkalinity of ash',
'magnesium', 'total phenols', 'flavanoids', 'nonflavanoid phenols',
'proanthocyanins', 'color intensity', 'hue', 'OD2800/OD315',
'proline')
############################ COMPLETE DATA ##################################
x <- wine$alcohol
mean(x) #1 3.00
var(x) # 0.66
plot(density(x))
hist(x, breaks=30)
# initial parameter estimates for normal mixture model: N(12.5, 0.5), N(13.7, 0.5)
EM_comp <- normalmixEM(x, k=2, lambda=c(0.5, 0.5), mu=c(12.5, 13.7),
sigma=c(0.5, 0.5))
# one iteration
# MCAR, p=0.1
# plot one simulation to construct an initial model
mcar_1 <- delete_MCAR(ds=wine, p=0.1, cols_mis='alcohol')
mean(mcar_1$alcohol, na.rm=TRUE) # 12.99
plot(density(mcar_1$alcohol, na.rm=TRUE)) # looks like a normal mixture
hist(mcar_1$alcohol, breaks=30)
x_mcar_1 <- mcar_1$alcohol[!is.na(mcar_1$alcohol)]
# initial parameters: N(12.4, 0.5) & N(13.7, 0.5)
EM_mcar_1 <- normalmixEM(x_mcar_1, k=2, lambda=c(0.5, 0.5), mu=c(12.4, 13.7),
sigma=c(0.5, 0.5)) # 121 iterations
# new parameter estimates for normal mixture model:
EM_mcar_1$mu
EM_mcar_1$sigma
EM_mcar_1$lambda
# overall mean and variance
emmean(EM_mcar_1, 2) # 13.02
emvar(EM_mcar_1, 2) # 0.66
# function to calculate the overall mean of a normal mixture model
emmean <- function(emobject, k) {
mean <- 0
for (i in 1:k) {
mean <- mean + emobject$lambda[i]*emobject$mu[i]
}
return(mean)
}
emmean(EM_comp, 2) # 13.00
# function to calculate the overall variance of a normal mixture model
emvar <- function(emobject, k) {
var <- 0
minus <- 0
for (i in 1:k) {
var <- var + emobject$lambda[i]*(emobject$sigma[i]^2 + emobject$mu[i]^2)
minus <- minus + emobject$lambda[i]*emobject$mu[i]
}
var <- var - minus^2
return(var)
}
emvar(EM_comp, 2) # 0.66
# function to run a t-test by hand (without data)
pttest <- function(mu1, mu2, sigma1, sigma2, d1, d2) {
n1 <- length(d1)
n2 <- length(d2)
df <- n1 + n2 - 2
se <- sqrt((sigma1^2 / n1) + (sigma2^2 / n2))
t <- (mu1-mu2)/se
pval <- pt(t, df)
return(pval)
}
pFtest <- function(d1, d2, sigma1, sigma2) {
df1 <- length(d1) - 1
df2 <- length(d2) - 1
F <- sigma1^2 / sigma2^2
pval <- pf(F, df1, df2)
return(pval)
}
# one iteration
# MCAR, p=0.1
# plot one simulation to construct an initial model
mcar_1 <- delete_MCAR(ds=wine, p=0.1, cols_mis='alcohol')
mean(mcar_1$alcohol, na.rm=TRUE) # 12.99
plot(density(mcar_1$alcohol, na.rm=TRUE)) # looks like a normal mixture
hist(mcar_1$alcohol, breaks=30)
x_mcar_1 <- mcar_1$alcohol[!is.na(mcar_1$alcohol)]
# initial parameters: N(12.4, 0.5) & N(13.7, 0.5)
EM_mcar_1 <- normalmixEM(x_mcar_1, k=2, lambda=c(0.5, 0.5), mu=c(12.4, 13.7),
sigma=c(0.5, 0.5)) # 121 iterations
# new parameter estimates for normal mixture model:
EM_mcar_1$mu
EM_mcar_1$sigma
EM_mcar_1$lambda
# overall mean and variance
emmean(EM_mcar_1, 2) # 13.02
emvar(EM_mcar_1, 2) # 0.66
# MAR, p=0.1
mar_1 <- delete_MAR_censoring(ds=wine, p=0.1, cols_mis='alcohol', cols_ctrl='ash')
plot(density(mar_1$alcohol, na.rm=TRUE))
# N(12.3, 0.5), N(13.7, 0.5)
nsim <- 100
means <- rep(0, nsim)
vars <- rep(0, nsim)
ts <- rep(0, nsim)
Fs <- rep(0, nsim)
s <- 1646
for (i in 1:nsim) {
mar_1 <- delete_MAR_censoring(ds=wine, p=0.1, cols_mis='alcohol', cols_ctrl='ash')
x_mar_1 <- mar_1$alcohol[!is.na(mar_1$alcohol)]
# initial parameter estimates: N(12.4, 0.5), N(13.7, 0.5), equally weighted
EM_mar_1 <- normalmixEM(x_mar_1, k=2, lambda=c(0.5, 0.5), mu=c(12.3, 13.7),
sigma=c(0.5, 0.5))
# overall means and variances
means[i] <- emmean(EM_mar_1, 2)
vars[i] <- emvar(EM_mar_1, 2)
# t-tests and F-tests
ts[i] <- pttest(mean(wine$alcohol), means[i], sqrt(var(wine$alcohol)), sqrt(vars[i]), wine$alcohol, x_mar_1)
Fs[i] <- pFtest(wine$alcohol, x_mar_1, sqrt(var(wine$alcohol)), sqrt(vars[i]))
s <- s+1
}
length(ts[ts<=0.05]) # 0
length(Fs[Fs<=0.05]) # 0
# 100 simulations of MCAR, p=0.1
nsim <- 100
means <- rep(0, nsim)
vars <- rep(0, nsim)
ts <- rep(0, nsim)
Fs <- rep(0, nsim)
s <- 1646
for (i in 1:nsim) {
mcar_1 <- delete_MCAR(ds=wine, p=0.1, cols_mis='alcohol')
x_mcar_1 <- mcar_1$alcohol[!is.na(mcar_1$alcohol)]
# initial parameter estimates: N(12.4, 0.5), N(13.7, 0.5), equally weighted
EM_mcar_1 <- normalmixEM(x_mcar_1, k=2, lambda=c(0.5, 0.5), mu=c(12.4, 13.7),
sigma=c(0.5, 0.5))
# overall means and variances
means[i] <- emmean(EM_mcar_1, 2)
vars[i] <- emvar(EM_mcar_1, 2)
# t-tests and F-tests
ts[i] <- pttest(mean(wine$alcohol), means[i], sqrt(var(wine$alcohol)), sqrt(vars[i]), wine$alcohol, x_mcar_1)
Fs[i] <- pFtest(wine$alcohol, x_mcar_1, sqrt(var(wine$alcohol)), sqrt(vars[i]))
s <- s+1
}
length(ts[ts<=0.05]) # 0
length(Fs[Fs<=0.05]) # 0
# plot once to determine initial parameter estimates
mcar_3 <- delete_MCAR(ds=wine, p=0.3, cols_mis='alcohol')
plot(density(mcar_3$alcohol, na.rm=TRUE))
# N(12.2, 0.5), N(13.1, 1)
nsim <- 100
means <- rep(0, nsim)
vars <- rep(0, nsim)
ts <- rep(0, nsim)
Fs <- rep(0, nsim)
s <- 1646
for (i in 1:nsim) {
mcar_3 <- delete_MCAR(ds=wine, p=0.3, cols_mis='alcohol')
x_mcar_3 <- mcar_3$alcohol[!is.na(mcar_3$alcohol)]
# initial parameter estimates: N(12.4, 0.5), N(13.7, 0.5), equally weighted
EM_mcar_3 <- normalmixEM(x_mcar_3, k=2, lambda=c(0.5, 0.5), mu=c(12.2, 13.1),
sigma=c(0.5, 1))
# overall means and variances
means[i] <- emmean(EM_mcar_3, 2)
vars[i] <- emvar(EM_mcar_3, 2)
# t-tests and F-tests
ts[i] <- pttest(mean(wine$alcohol), means[i], sqrt(var(wine$alcohol)), sqrt(vars[i]), wine$alcohol, x_mcar_3)
Fs[i] <- pFtest(wine$alcohol, x_mcar_3, sqrt(var(wine$alcohol)), sqrt(vars[i]))
s <- s+1
}
length(ts[ts<=0.05]) # 0
length(Fs[Fs<=0.05]) # 0
# MCAR, p=0.5
# plot once to determine initial parameter estimates
mcar_5 <- delete_MCAR(ds=wine, p=0.5, cols_mis='alcohol')
plot(density(mcar_5$alcohol, na.rm=TRUE))
# N(12.5, 0.5), N(13.7, 0.5)
nsim <- 100
means <- rep(0, nsim)
vars <- rep(0, nsim)
ts <- rep(0, nsim)
Fs <- rep(0, nsim)
s <- 1646
for (i in 1:nsim) {
mcar_5 <- delete_MCAR(ds=wine, p=0.5, cols_mis='alcohol')
x_mcar_5 <- mcar_5$alcohol[!is.na(mcar_5$alcohol)]
# initial parameter estimates: N(12.4, 0.5), N(13.7, 0.5), equally weighted
EM_mcar_5 <- normalmixEM(x_mcar_5, k=2, lambda=c(0.5, 0.5), mu=c(12.5, 13.7),
sigma=c(0.5, 0.5))
# overall means and variances
means[i] <- emmean(EM_mcar_5, 2)
vars[i] <- emvar(EM_mcar_5, 2)
# t-tests and F-tests
ts[i] <- pttest(mean(wine$alcohol), means[i], sqrt(var(wine$alcohol)), sqrt(vars[i]), wine$alcohol, x_mcar_3)
Fs[i] <- pFtest(wine$alcohol, x_mcar_3, sqrt(var(wine$alcohol)), sqrt(vars[i]))
s <- s+1
}
length(ts[ts<=0.05]) # 0
length(Fs[Fs<=0.05]) # 1
# MCAR, p=0.7
# plot once to determine initial parameter estimates
mcar_7 <- delete_MCAR(ds=wine, p=0.7, cols_mis='alcohol')
plot(density(mcar_7$alcohol, na.rm=TRUE))
# N(12.5, 0.5), N(13.5, 0.5)
nsim <- 100
means <- rep(0, nsim)
vars <- rep(0, nsim)
ts <- rep(0, nsim)
Fs <- rep(0, nsim)
s <- 1646
for (i in 1:nsim) {
mcar_7 <- delete_MCAR(ds=wine, p=0.7, cols_mis='alcohol')
x_mcar_7 <- mcar_7$alcohol[!is.na(mcar_7$alcohol)]
# initial parameter estimates: N(12.4, 0.5), N(13.7, 0.5), equally weighted
EM_mcar_7 <- normalmixEM(x_mcar_7, k=2, lambda=c(0.5, 0.5), mu=c(12.5, 13.5),
sigma=c(0.5, 0.5))
# overall means and variances
means[i] <- emmean(EM_mcar_7, 2)
vars[i] <- emvar(EM_mcar_7, 2)
# t-tests and F-tests
ts[i] <- pttest(mean(wine$alcohol), means[i], sqrt(var(wine$alcohol)), sqrt(vars[i]), wine$alcohol, x_mcar_3)
Fs[i] <- pFtest(wine$alcohol, x_mcar_3, sqrt(var(wine$alcohol)), sqrt(vars[i]))
s <- s+1
}
length(ts[ts<=0.05]) # 6
length(Fs[Fs<=0.05]) # 0
